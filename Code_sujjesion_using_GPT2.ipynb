{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code_sujjesion_using_GPT2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlws3SMyt9Yu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ac31e5b-5b8c-4c09-8b88-175910aca591"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHq1Ad0KucXC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "8f01a6a6-f4b5-4fbc-8747-63c8c0e424f2"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/f4/9f93f06dd2c57c7cd7aa515ffbf9fcfd8a084b92285732289f4a5696dd91/transformers-3.2.0-py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 16.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 34.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 47.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=2ec535b2e3a628290fe85afed2505d23e3371987938e4387423c32d6b5cd3816\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB2y_8LsuehF"
      },
      "source": [
        "from transformers import GPT2LMHeadModel,GPT2Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRPFAcoGtg6l"
      },
      "source": [
        "output_dir = '/content/gdrive/My Drive/distilled_gpt2/code_gen/'\n",
        "model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_4BSShhujy8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "924a49da-af4c-4a13-838c-d8d0b8c4939a"
      },
      "source": [
        "sample = \"model = Sequential() model.add(ConvLSTM2D\"\n",
        "print(\"input :  \\n\")\n",
        "print(sample)\n",
        "input_ids = tokenizer.encode(sample, return_tensors='pt')\n",
        "beam_outputs = model.generate(\n",
        "    input_ids, \n",
        "    max_length=250\n",
        ")\n",
        "\n",
        "# now we have 3 output sequences\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(beam_outputs[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "input :  \n",
            "\n",
            "model = Sequential() model.add(ConvLSTM2D\n",
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "model = Sequential() model.add(ConvLSTM2D(128, (3, 3), activation='relu'))\n",
            "    model.add(ZeroPadding2D((1,1)))\n",
            "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
            "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
            "\n",
            "    model.add(ZeroPadding2D((1,1)))\n",
            "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
            "    model.add(ZeroPadding2D((1,1)))\n",
            "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
            "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
            "\n",
            "    model.add(ZeroPadding2D((1,1)))\n",
            "    model.add(Conv2D(256, (3, 3), activation='\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qltg4PWvW8s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "d3c142b8-b53c-4159-cc7b-d9968d486c3e"
      },
      "source": [
        "sample = \"\"\"class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\"\"\"\n",
        "print(\"input :  \\n\")\n",
        "print(sample)\n",
        "input_ids = tokenizer.encode(sample, return_tensors='pt')\n",
        "beam_outputs = model.generate(\n",
        "    input_ids, \n",
        "    max_length=350\n",
        ")\n",
        "\n",
        "# now we have 3 output sequences\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(beam_outputs[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "input :  \n",
            "\n",
            "class Net(nn.Module):\n",
            "    def __init__(self):\n",
            "        super(Net, self).__init__()\n",
            "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "class Net(nn.Module):\n",
            "    def __init__(self):\n",
            "        super(Net, self).__init__()\n",
            "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
            "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
            "        self.dropout1 = nn.Dropout2d(0.25)\n",
            "        self.dropout2 = nn.Dropout2d(0.5)\n",
            "        self.fc1 = nn.Linear(9216, 128)\n",
            "        self.fc2 = nn.Linear(128, 10)\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = self.conv1(x)\n",
            "        x = F.relu(x)\n",
            "        x = self.conv2(x)\n",
            "           x = F.max_pool2d(x=2d\n",
            "                     # F.view_fc1\n",
            "                                         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2-O-7gdv-Xv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "09dd9072-58e5-49d9-f802-0e5ec741c76f"
      },
      "source": [
        "sample = \"\"\"\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\"\"\"\n",
        "print(\"input :  \\n\")\n",
        "print(sample)\n",
        "input_ids = tokenizer.encode(sample, return_tensors='pt')\n",
        "beam_outputs = model.generate(\n",
        "    input_ids, \n",
        "    max_length=350\n",
        ")\n",
        "\n",
        "# now we have 3 output sequences\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(beam_outputs[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "input :  \n",
            "\n",
            "\n",
            "from keras.preprocessing import sequence\n",
            "from keras.models import Sequential\n",
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "from keras.preprocessing import sequence\n",
            "from keras.models import Sequential\n",
            "from keras.layers import Dense, Dropout, Activation, Conv1D, MaxPooling1D, Embedding, Flatten\n",
            "from keras import optimizers\n",
            "\n",
            "num_features = 3000\n",
            "sequence_length = 300\n",
            "embedding_dimension = 100\n",
            "\n",
            "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = num_features)\n",
            "\n",
            "X_train = pad_sequences(X_train, maxlen = sequence_length)\n",
            "X_test = pad_sequences(X_test, maxlen = sequence_length)\n",
            "\n",
            "filter_sizes = [3, 4, 5]\n",
            "\n",
            "def convolution():\n",
            "    inn = Input(shape = (sequence_length, embedding_dimension, 1))\n",
            "    convolutions = []\n",
            "    # we conduct three convolutions & poolings then concatenate them.\n",
            "    for fs in filter_sizes:\n",
            "        conv = Conv2D(filters = 100, kernel_size = (fs, embedding_dimension), strides = 1), padding = 1), strides = 1, padding = \"valid\")(inn)\n",
            "                                                            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA9dJC54xGEa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "d8fdb011-169d-4a94-e9fa-5e71a4737d30"
      },
      "source": [
        "sample = \"\"\"model = keras.Sequential([\n",
        "    keras.layers\"\"\"\n",
        "print(\"input :  \\n\")\n",
        "print(sample)\n",
        "input_ids = tokenizer.encode(sample, return_tensors='pt')\n",
        "beam_outputs = model.generate(\n",
        "    input_ids, \n",
        "    max_length=120\n",
        ")\n",
        "\n",
        "# now we have 3 output sequences\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(beam_outputs[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "input :  \n",
            "\n",
            "model = keras.Sequential([\n",
            "    keras.layers\n",
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "model = keras.Sequential([\n",
            "    keras.layers.Dense(256, input_dim=784),\n",
            "    Activation('relu'),\n",
            "    Dense(10),\n",
            "    Activation('softmax')\n",
            "]\n",
            "\n",
            "model.compile(loss='categorical_crossentropy',\n",
            "              optimizer='adam',\n",
            "              metrics=['accuracy'])\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}